{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4f41a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af67cd65",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Shirw\\\\OneDrive\\\\Desktop\\\\Lead Scoring Assignment\\\\Leads.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13432\\3078715893.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mLead_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"C:\\Users\\Shirw\\OneDrive\\Desktop\\Lead Scoring Assignment\\Leads.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mLead_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Shirw\\\\OneDrive\\\\Desktop\\\\Lead Scoring Assignment\\\\Leads.csv'"
     ]
    }
   ],
   "source": [
    "Lead_data = pd.read_csv(r\"C:\\Users\\Shirw\\OneDrive\\Desktop\\Lead Scoring Assignment\\Leads.csv\")\n",
    "Lead_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eea6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lead_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bea054",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lead_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dce8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lead_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86c596a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicate \n",
    "Lead_data.duplicated(subset = ['Prospect ID'], keep = False).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015959ac",
   "metadata": {},
   "source": [
    "No duplicate values in Prospect ID and Lead Number\n",
    "\n",
    "Clearly Prospect ID & Lead Number are two variables that are just indicative of the ID number of the Contacted People & can be dropped.\n",
    "\n",
    "EXPLORATORY DATA ANALYSIS\n",
    "Data Cleaning & Treatment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecf1a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping Lead Number and Prospect ID since they have all unique values\n",
    "\n",
    "Lead_data.drop(['Prospect ID', 'Lead Number'], 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5053f630",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting 'Select' values to NaN.\n",
    "\n",
    "Lead_data = Lead_data.replace('Select', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a369b200",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lead_data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b399fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unique valued columns\n",
    "Lead_data= Lead_data.drop(['Magazine','Receive More Updates About Our Courses','I agree to pay the amount through cheque','Get updates on DM Content','Update me on Supply Chain Content'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30693d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking null values in each rows\n",
    "\n",
    "Lead_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc8cbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % of null value\n",
    "round(100*(Lead_data.isnull().sum())/len(Lead_data.index),2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa8f497",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping cols with more than 45% missing values\n",
    "\n",
    "Lead_data = Lead_data.drop(['Asymmetrique Profile Score','Asymmetrique Activity Score','Asymmetrique Profile Index','Asymmetrique Activity Index','Lead Profile','Lead Quality','How did you hear about X Education',],axis =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dbe92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lead_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710144c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking null values percentage\n",
    "\n",
    "round(100*(Lead_data.isnull().sum()/len(Lead_data.index)), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84253767",
   "metadata": {},
   "source": [
    "There is a huge value of null variables in some columns as seen above. But removing the rows with the null value will cost us a lot of data and they are important columns. So, instead we are going to replace the NaN values with 'not provided'. This way we have all the data and almost no null values. In case these come up in the model, it will be of no use and we can drop it off then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a959b804",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lead_data['Specialization'] = Lead_data['Specialization'].fillna('not provided')\n",
    "Lead_data['City'] = Lead_data['City'].fillna('not provided')\n",
    "Lead_data['Tags'] = Lead_data['Tags'].fillna('not provided')\n",
    "Lead_data['What matters most to you in choosing a course'] = Lead_data['What matters most to you in choosing a course'].fillna('not provided')\n",
    "Lead_data['What is your current occupation'] = Lead_data['What is your current occupation'].fillna('not provided')\n",
    "Lead_data['Country'] = Lead_data['Country'].fillna('not provided')\n",
    "Lead_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530e54c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking null values percentage\n",
    "\n",
    "round(100*(Lead_data.isnull().sum()/len(Lead_data.index)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666a3e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lead_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2d2f9d",
   "metadata": {},
   "source": [
    "# Categorical Attributes Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85085f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lead_data['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cf6b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slots(x):\n",
    "    category = \"\"\n",
    "    if x == \"India\":\n",
    "        category = \"India\"\n",
    "    elif x == \"not provided\":\n",
    "        category = \"not provided\"\n",
    "    else:\n",
    "        category = \"outside india\"\n",
    "    return category\n",
    "\n",
    "Lead_data['Country'] = Lead_data.apply(lambda x:slots(x['Country']), axis = 1)\n",
    "Lead_data['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df583fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since India is the most common occurence among the non-missing values we can impute all not provided values with India\n",
    "\n",
    "Lead_data['Country'] = Lead_data['Country'].replace('not provided','India')\n",
    "Lead_data['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0aa4048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the percent of lose if the null values are removed\n",
    "round(100*(sum(Lead_data.isnull().sum(axis=1) > 1)/Lead_data.shape[0]),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27bfe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lead_data = Lead_data[Lead_data.isnull().sum(axis=1) <1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68767113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rechecking the percentage of missing values\n",
    "round(100*(Lead_data.isnull().sum()/len(Lead_data.index)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f3a61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lead_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e50b98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting spread of Country columnn after replacing NaN values\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "s1=sns.countplot(Lead_data.Country, hue=Lead_data.Converted)\n",
    "s1.set_xticklabels(s1.get_xticklabels(),rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a0fb9c",
   "metadata": {},
   "source": [
    "As we can see the Number of Values for India are quite high (nearly 97% of the Data), this column can be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8dc7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a list of columns to be droppped\n",
    "\n",
    "cols_to_drop=['Country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbd33c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking value counts of \"City\" column\n",
    "\n",
    "Lead_data['City'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858a809a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting spread of City columnn\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "s1=sns.countplot(Lead_data.City, hue=Lead_data.Converted)\n",
    "s1.set_xticklabels(s1.get_xticklabels(),rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a6c6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,40))\n",
    "\n",
    "plt.subplot(6,2,1)\n",
    "sns.countplot(Lead_data['Lead Origin'])\n",
    "plt.title('Lead Origin')\n",
    "\n",
    "plt.subplot(6,2,2)\n",
    "sns.countplot(Lead_data['Do Not Email'])\n",
    "plt.title('Do Not Email')\n",
    "\n",
    "plt.subplot(6,2,3)\n",
    "sns.countplot(Lead_data['Do Not Call'])\n",
    "plt.title('Do Not Call')\n",
    "\n",
    "plt.subplot(6,2,4)\n",
    "sns.countplot(Lead_data['Country'])\n",
    "plt.title('Country')\n",
    "\n",
    "plt.subplot(6,2,5)\n",
    "sns.countplot(Lead_data['Search'])\n",
    "plt.title('Search')\n",
    "plt.subplot(6,2,6)\n",
    "sns.countplot(Lead_data['Newspaper Article'])\n",
    "plt.title('Newspaper Article')\n",
    "\n",
    "plt.subplot(6,2,7)\n",
    "sns.countplot(Lead_data['X Education Forums'])\n",
    "plt.title('X Education Forums')\n",
    "\n",
    "plt.subplot(6,2,8)\n",
    "sns.countplot(Lead_data['Newspaper'])\n",
    "plt.title('Newspaper')\n",
    "\n",
    "plt.subplot(6,2,9)\n",
    "sns.countplot(Lead_data['Digital Advertisement'])\n",
    "plt.title('Digital Advertisement')\n",
    "\n",
    "plt.subplot(6,2,10)\n",
    "sns.countplot(Lead_data['Through Recommendations'])\n",
    "plt.title('Through Recommendations')\n",
    "\n",
    "plt.subplot(6,2,11)\n",
    "sns.countplot(Lead_data['A free copy of Mastering The Interview'])\n",
    "plt.title('A free copy of Mastering The Interview')\n",
    "plt.subplot(6,2,12)\n",
    "sns.countplot(Lead_data['Last Notable Activity']).tick_params(axis='x', rotation = 90)\n",
    "plt.title('Last Notable Activity')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f954fc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(Lead_data['Lead Source']).tick_params(axis='x', rotation = 90)\n",
    "plt.title('Lead Source')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672eb682",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,30))\n",
    "plt.subplot(2,2,1)\n",
    "sns.countplot(Lead_data['Specialization']).tick_params(axis='x', rotation = 90)\n",
    "plt.title('Specialization')\n",
    "plt.subplot(2,2,2)\n",
    "sns.countplot(Lead_data['What is your current occupation']).tick_params(axis='x', rotation = 90)\n",
    "plt.title('Current Occupation')\n",
    "plt.subplot(2,2,3)\n",
    "sns.countplot(Lead_data['What matters most to you in choosing a course']).tick_params(axis='x', rotation = 90)\n",
    "plt.title('What matters most to you in choosing a course')\n",
    "plt.subplot(2,2,4)\n",
    "sns.countplot(Lead_data['Last Activity']).tick_params(axis='x', rotation = 90)\n",
    "plt.title('Last Activity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5580c66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(Lead_data['Converted'])\n",
    "plt.title('Converted(\"Y variable\")')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05a43c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fec7746",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "plt.subplot(221)\n",
    "plt.hist(Lead_data['TotalVisits'], bins = 200)\n",
    "plt.title('Total Visits')\n",
    "plt.xlim(0,25)\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.hist(Lead_data['Total Time Spent on Website'], bins = 10)\n",
    "plt.title('Total Time Spent on Website')\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.hist(Lead_data['Page Views Per Visit'], bins = 20)\n",
    "plt.title('Page Views Per Visit')\n",
    "plt.xlim(0,20)\n",
    "plt.show( ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f4c2c2",
   "metadata": {},
   "source": [
    "# Relating all the categorical variables to Converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be3de2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "sns.countplot(x='Lead Origin', hue='Converted', data= Lead_data).tick_params(axis='x', rotation = 90)\n",
    "plt.title('Lead Origin')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "sns.countplot(x='Lead Source', hue='Converted', data= Lead_data).tick_params(axis='x', rotation = 90)\n",
    "plt.title('Lead Source')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45055cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10 ,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.countplot(x='Do Not Email', hue='Converted', data= Lead_data).tick_params(axis='x', rotation = 90)\n",
    "plt.title('Do Not Email')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.countplot(x='Do Not Call', hue='Converted', data= Lead_data).tick_params(axis='x', rotation = 90)\n",
    "plt.title('Do Not Call')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb9f349",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "sns.countplot(x='Last Activity', hue='Converted', data= Lead_data).tick_params(axis='x', rotation = 90)\n",
    "plt.title('Last Activity')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.countplot(x='Country', hue='Converted', data= Lead_data).tick_params(axis='x', rotation = 90)\n",
    "plt.title('Country')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcec5f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "sns.countplot(x='Specialization', hue='Converted', data= Lead_data).tick_params(axis='x', rotation = 90)\n",
    "plt.title('Specialization')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.countplot(x='What is your current occupation', hue='Converted', data= Lead_data).tick_params(axis='x', rotation = 90)\n",
    "plt.title('What is your current occupation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f18da2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "sns.countplot(x='What matters most to you in choosing a course', hue='Converted', data= Lead_data).tick_params(axis='x', rotation = 90)\n",
    "plt.title('What matters most to you in choosing a course')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.countplot(x='Search', hue='Converted', data= Lead_data).tick_params(axis='x', rotation = 90)\n",
    "plt.title('Search')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62e80e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "sns.countplot(x='Newspaper Article', hue='Converted', data= Lead_data).tick_params(axis='x', rotation = 90)\n",
    "plt.title('Newspaper Article')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.countplot(x='X Education Forums', hue='Converted', data= Lead_data).tick_params(axis='x', rotation = 90)\n",
    "plt.title('X Education Forums')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a258f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "sns.countplot(x='Newspaper', hue='Converted', data= Lead_data).tick_params(axis='x', rotation = 90)\n",
    "plt.title('Newspaper')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.countplot(x='Digital Advertisement', hue='Converted', data= Lead_data).tick_params(axis='x', rotation = 90)\n",
    "plt.title('Digital Advertisement')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b5d565",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "sns.countplot(x='Through Recommendations', hue='Converted', data= Lead_data).tick_params(axis='x', rotation = 90)\n",
    "plt.title('Through Recommendations')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.countplot(x='A free copy of Mastering The Interview', hue='Converted', data= Lead_data).tick_params(axis='x', rotation = 90)\n",
    "plt.title('A free copy of Mastering The Interview')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddf805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Last Notable Activity', hue='Converted', data= Lead_data).tick_params(axis='x', rotation = 90)\n",
    "plt.title('Last Notable Activity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccba7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check the correlation among varibles\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.heatmap(Lead_data.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab6ddb2",
   "metadata": {},
   "source": [
    "It is understandable from the above EDA that there are many elements that have very little data and so will be of less relevance to our analysis."
   ]
  },
  {
   "cell_type": "raw",
   "id": "f6e44cb7",
   "metadata": {},
   "source": [
    "Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037c521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = Lead_data[['TotalVisits','Total Time Spent on Website','Page Views Per Visit']]\n",
    "numeric.describe(percentiles=[0.25,0.5,0.75,0.9,0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8275b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5,5))\n",
    "sns.boxplot(y=Lead_data['TotalVisits'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22104bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y=Lead_data['Total Time Spent on Website'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fcd885",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y=Lead_data['Page Views Per Visit'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256632d7",
   "metadata": {},
   "source": [
    "We can see presence of outliers in TotalVisits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32957762",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outlier Treatment: Remove top & bottom 1% of the Column Outlier values\n",
    "\n",
    "Q3 = Lead_data.TotalVisits.quantile(0.99)\n",
    "Lead_data = Lead_data[(Lead_data.TotalVisits <= Q3)]\n",
    "Q1 = Lead_data.TotalVisits.quantile(0.01)\n",
    "Lead_data = Lead_data[(Lead_data.TotalVisits >= Q1)]\n",
    "sns.boxplot(y=Lead_data['TotalVisits'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66045b4d",
   "metadata": {},
   "source": [
    "# Dummy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5175e702",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of columns to be dropped\n",
    "cols_to_drop=['Country','Tags']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9af58cc",
   "metadata": {},
   "source": [
    "We can drop \"Tags\" ,As tags variable is generated by the sales sales team after the disscussion with student otherwise it will increase the model accuracy ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79246541",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping columns\n",
    "Lead_data = Lead_data.drop(cols_to_drop,1)\n",
    "Lead_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1250aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting a list of categorical columns\n",
    "\n",
    "cat_cols= Lead_data.select_dtypes(include=['object']).columns\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4ebf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables using the 'get_dummies'\n",
    "dummy = pd.get_dummies(Lead_data[['Lead Origin','Specialization' ,'Lead Source', 'Do Not Email', 'Last Activity', 'What is your current occupation','A free copy of Mastering The Interview', 'Last Notable Activity']], drop_first=True)\n",
    "# Add the results to the master dataframe\n",
    "Lead_data_dum = pd.concat([Lead_data, dummy], axis=1)\n",
    "Lead_data_dum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55873bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lead_data_dum = Lead_data_dum.drop(['City','What is your current occupation_not provided','Lead Origin', 'Lead Source', 'Do Not Email', 'Do Not Call','Last Activity', 'Specialization', 'Specialization_not provided','What is your current occupation','What matters most to you in choosing a course', 'Search','Newspaper Article', 'X Education Forums', 'Newspaper','Digital Advertisement', 'Through Recommendations','A free copy of Mastering The Interview', 'Last Notable Activity'], 1)\n",
    "Lead_data_dum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df9c3f9",
   "metadata": {},
   "source": [
    "# Test-Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d53e30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the required library\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdd9632",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Lead_data_dum.drop(['Converted'], 1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eeef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting the target variable in y\n",
    "y = Lead_data_dum['Converted']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a80f354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into 70% and 30% for train and test respectively\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778f07d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MinMax scaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Scale the three numeric features\n",
    "scaler = MinMaxScaler()\n",
    "X_train[['TotalVisits', 'Page Views Per Visit', 'Total Time Spent on Website']] = scaler.fit_transform(X_train[['TotalVisits', 'Page Views Per Visit', 'Total Time Spent on Website']])\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dc9de2",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9304e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 'LogisticRegression'\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e70e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RFE\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd72ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running RFE with 15 variables as output\n",
    "rfe = RFE(estimator=LogisticRegression(), n_features_to_select=20)\n",
    "rfe = rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f13877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features that have been selected by RFE\n",
    "list(zip(X_train.columns, rfe.support_, rfe.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c724dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all the columns selected by RFE in the variable 'col'\n",
    "col = X_train.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c6142b",
   "metadata": {},
   "source": [
    "All the variables selected by RFE, next statistics part (p-values and the VIFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044afd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting columns selected by RFE\n",
    "X_train = X_train[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5067aa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing statsmodels\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a784eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = sm.add_constant(X_train)\n",
    "logm1 = sm.GLM(y_train, X_train_sm, family = sm.families.Binomial())\n",
    "res = logm1.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9744a056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing 'variance_inflation_factor'\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c07fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a VIF dataframe for all the variables present\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be830c62",
   "metadata": {},
   "source": [
    "The VIF values seem fine but some p-values are 99 %. So removing ' What is your current occupation_Housewife','Last Notable Activity_Had a Phone Conversation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a18d73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(['What is your current occupation_Housewife','Last Notable Activity_Had a Phone Conversation'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727eca35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit the model with the new set of features\n",
    "X_train_sm = sm.add_constant(X_train)\n",
    "logm3 = sm.GLM(y_train, X_train_sm, family = sm.families.Binomial())\n",
    "res = logm3.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974a6908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a VIF dataframe for all the variables present\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5055e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop('Page Views Per Visit', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a79e88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit the model with the new set of features\n",
    "X_train_sm = sm.add_constant(X_train)\n",
    "logm3 = sm.GLM(y_train, X_train_sm, family = sm.families.Binomial())\n",
    "res = logm3.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e464bf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a VIF dataframe for all the variables present\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e1c2b0",
   "metadata": {},
   "source": [
    "All the VIF values are good and all the p-values are below 0.05. So we can fix model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c94eae0",
   "metadata": {},
   "source": [
    "# Creating Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f7d3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the probabilities on the train set\n",
    "y_train_pred = res.predict(X_train_sm)\n",
    "y_train_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a1b4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping to an array\n",
    "y_train_pred = y_train_pred.values.reshape(-1)\n",
    "y_train_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7452461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data frame with given convertion rate and probablity of predicted ones\n",
    "y_train_pred_final = pd.DataFrame({'Converted':y_train.values, 'Conversion_Prob':y_train_pred})\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6448a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituting 0 or 1 with the cut off as 0.5\n",
    "y_train_pred_final['Predicted'] = y_train_pred_final.Conversion_Prob.map(lambda x: 1 if x > 0.5 else 0)\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db2c99f",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dccf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing metrics from sklearn for evaluation\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4f7afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating confusion matrix \n",
    "confusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.Predicted )\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3adb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted        No         Yes\n",
    "# Actual\n",
    "# No              3498      417\n",
    "# Yes             837      1541"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0547d040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the overall accuracy\n",
    "metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.Predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397a0780",
   "metadata": {},
   "source": [
    "That's around 82% accuracy with is a very good value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5968dc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituting the value of true positive\n",
    "TP = confusion[1,1]\n",
    "# Substituting the value of true negatives\n",
    "TN = confusion[0,0]\n",
    "# Substituting the value of false positives\n",
    "FP = confusion[0,1] \n",
    "# Substituting the value of false negatives\n",
    "FN = confusion[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019e4e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the sensitivity\n",
    "TP/(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f8fe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the specificity\n",
    "TN/(TN+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc14e4b",
   "metadata": {},
   "source": [
    "With the current cut off as 0.5 we have around 82% accuracy, sensitivity of around 70% and specificity of around 88%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3112d91",
   "metadata": {},
   "source": [
    "# Optimise Cut off (ROC Curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccbb0af",
   "metadata": {},
   "source": [
    "The previous cut off was randomely selected. Now to find the optimum one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c823459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC function\n",
    "def draw_roc( actual, probs ):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n",
    "                                              drop_intermediate = False )\n",
    "    auc_score = metrics.roc_auc_score( actual, probs )\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abbc572",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve( y_train_pred_final.Converted, y_train_pred_final.Conversion_Prob, drop_intermediate = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a187e61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the ROC function\n",
    "draw_roc(y_train_pred_final.Converted, y_train_pred_final.Conversion_Prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cfc5fb",
   "metadata": {},
   "source": [
    "The area under ROC curve is 0.88 which is a very good value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f90fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating columns with different probability cutoffs \n",
    "numbers = [float(x)/10 for x in range(10)]\n",
    "for i in numbers:\n",
    "    y_train_pred_final[i]= y_train_pred_final.Conversion_Prob.map(lambda x: 1 if x > i else 0)\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29138d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe to see the values of accuracy, sensitivity, and specificity at different values of probabiity cutoffs\n",
    "cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n",
    "# Making confusing matrix to find values of sensitivity, accurace and specificity for each level of probablity\n",
    "from sklearn.metrics import confusion_matrix\n",
    "num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "for i in num:\n",
    "    cm1 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final[i] )\n",
    "    total1=sum(sum(cm1))\n",
    "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
    "    \n",
    "    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
    "cutoff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a03ec10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting it\n",
    "cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f79e3b",
   "metadata": {},
   "source": [
    "From the graph it is visible that the optimal cut off is at 0.35."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e3511e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['final_predicted'] = y_train_pred_final.Conversion_Prob.map( lambda x: 1 if x > 0.35 else 0)\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfed68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the overall accuracy\n",
    "metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e54076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating confusion matrix \n",
    "confusion2 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.final_predicted )\n",
    "confusion2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d180bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituting the value of true positive\n",
    "TP = confusion2[1,1]\n",
    "# Substituting the value of true negatives\n",
    "TN = confusion2[0,0]\n",
    "# Substituting the value of false positives\n",
    "FP = confusion2[0,1] \n",
    "# Substituting the value of false negatives\n",
    "FN = confusion2[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9edb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the sensitivity\n",
    "TP/(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bba87a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the specificity\n",
    "TN/(TN+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42131fe4",
   "metadata": {},
   "source": [
    "With the current cut off as 0.35 we have accuracy, sensitivity and specificity of around 80%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de7abfb",
   "metadata": {},
   "source": [
    "# Prediction on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2f92ef",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Scaling numeric values\n",
    "X_test[['TotalVisits', 'Page Views Per Visit', 'Total Time Spent on Website']] = scaler.transform(X_test[['TotalVisits', 'Page Views Per Visit', 'Total Time Spent on Website']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a1a792",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3f3512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns in X_train for X_test as well\n",
    "X_test = X_test[col]\n",
    "# Add a constant to X_test\n",
    "X_test_sm = sm.add_constant(X_test[col])\n",
    "X_test_sm\n",
    "X_test_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262dc1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing prediction of test set in the variable 'y_test_pred'\n",
    "y_test_pred = res.predict(X_test_sm)\n",
    "# Coverting it to df\n",
    "y_pred_df = pd.DataFrame(y_test_pred)\n",
    "# Converting y_test to dataframe\n",
    "y_test_df = pd.DataFrame(y_test)\n",
    "# Remove index for both dataframes to append them side by side \n",
    "y_pred_df.reset_index(drop=True, inplace=True)\n",
    "y_test_df.reset_index(drop=True, inplace=True)\n",
    "# Append y_test_df and y_pred_df\n",
    "y_pred_final = pd.concat([y_test_df, y_pred_df],axis=1)\n",
    "# Renaming column \n",
    "y_pred_final= y_pred_final.rename(columns = {0 : 'Conversion_Prob'})\n",
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bbeda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making prediction using cut off 0.35\n",
    "y_pred_final['final_predicted'] = y_pred_final.Conversion_Prob.map(lambda x: 1 if x > 0.35 else 0)\n",
    "y_pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6ec5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the overall accuracy\n",
    "metrics.accuracy_score(y_pred_final['Converted'], y_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9c3fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating confusion matrix \n",
    "confusion2 = metrics.confusion_matrix(y_pred_final['Converted'], y_pred_final.final_predicted )\n",
    "confusion2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760f716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituting the value of true positive\n",
    "TP = confusion2[1,1]\n",
    "# Substituting the value of true negatives\n",
    "TN = confusion2[0,0]\n",
    "# Substituting the value of false positives\n",
    "FP = confusion2[0,1] \n",
    "# Substituting the value of false negatives\n",
    "FN = confusion2[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a886e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the sensitivity\n",
    "TP/(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dde69a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the specificity\n",
    "TN/(TN+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c357bea1",
   "metadata": {},
   "source": [
    "With the current cut off as 0.35 we have accuracy, sensitivity and specificity of around 80%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5ba3ac",
   "metadata": {},
   "source": [
    "# Precision-Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64284f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.Predicted )\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b6696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision = TP / TP + FP\n",
    "confusion[1,1]/(confusion[0,1]+confusion[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e20255",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recall = TP / TP + FN\n",
    "confusion[1,1]/(confusion[1,0]+confusion[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b7e31b",
   "metadata": {},
   "source": [
    "With the current cut off as 0.35 we have Precision around 79% and Recall around 70%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8921ce",
   "metadata": {},
   "source": [
    "Precision and recall tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251af422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e555332",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final.Converted, y_train_pred_final.Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6e64f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "p, r, thresholds = precision_recall_curve(y_train_pred_final.Converted, y_train_pred_final.Conversion_Prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70344902",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(thresholds, p[:-1], \"g-\")\n",
    "plt.plot(thresholds, r[:-1], \"r-\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04aedbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['final_predicted'] = y_train_pred_final.Conversion_Prob.map(lambda x: 1 if x > 0.41 else 0)\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ef4269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f6b544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating confusion matrix again\n",
    "confusion2 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.final_predicted )\n",
    "confusion2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4f2510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituting the value of true positive\n",
    "TP = confusion2[1,1]\n",
    "# Substituting the value of true negatives\n",
    "TN = confusion2[0,0]\n",
    "# Substituting the value of false positives\n",
    "FP = confusion2[0,1] \n",
    "# Substituting the value of false negatives\n",
    "FN = confusion2[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cb4a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision = TP / TP + FP\n",
    "TP / (TP + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5504b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recall = TP / TP + FN\n",
    "TP / (TP + FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5f1793",
   "metadata": {},
   "source": [
    "With the current cut off as 0.44 we have Precision around 76% and Recall around 76.3% and accuracy 82 %."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb425d4",
   "metadata": {},
   "source": [
    "# Prediction on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750490ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing prediction of test set in the variable 'y_test_pred'\n",
    "y_test_pred = res.predict(X_test_sm)\n",
    "# Coverting it to df\n",
    "y_pred_df = pd.DataFrame(y_test_pred)\n",
    "# Converting y_test to dataframe\n",
    "y_test_df = pd.DataFrame(y_test)\n",
    "# Remove index for both dataframes to append them side by side \n",
    "y_pred_df.reset_index(drop=True, inplace=True)\n",
    "y_test_df.reset_index(drop=True, inplace=True)\n",
    "# Append y_test_df and y_pred_df\n",
    "y_pred_final = pd.concat([y_test_df, y_pred_df],axis=1)\n",
    "# Renaming column \n",
    "y_pred_final= y_pred_final.rename(columns = {0 : 'Conversion_Prob'})\n",
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46732cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making prediction using cut off 0.41\n",
    "y_pred_final['final_predicted'] = y_pred_final.Conversion_Prob.map(lambda x: 1 if x > 0.44 else 0)\n",
    "y_pred_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af74ec3d",
   "metadata": {},
   "source": [
    "Check the overall accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb141b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the overall accuracy\n",
    "metrics.accuracy_score(y_pred_final['Converted'], y_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581ae404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating confusion matrix \n",
    "confusion2 = metrics.confusion_matrix(y_pred_final['Converted'], y_pred_final.final_predicted )\n",
    "confusion2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a7a8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituting the value of true positive\n",
    "TP = confusion2[1,1]\n",
    "# Substituting the value of true negatives\n",
    "TN = confusion2[0,0]\n",
    "# Substituting the value of false positives\n",
    "FP = confusion2[0,1] \n",
    "# Substituting the value of false negatives\n",
    "FN = confusion2[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1d6f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision = TP / TP + FP\n",
    "TP / (TP + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed37b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recall = TP / TP + FN\n",
    "TP / (TP + FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5f9d39",
   "metadata": {},
   "source": [
    "With the current cut off as 0.41 we have Precision around 75% , Recall around 73% and accuracy 80.5%.\n",
    "\n",
    "The Model seems to predict the Conversion Rate very well and we should be able to give the CEO confidence in making good calls based on this model\n",
    "\n",
    "Conclusion\n",
    "It was found that the variables that mattered the most in the potential buyers are (In descending order) :\n",
    "\n",
    "TotalVisits\n",
    "The total time spend on the Website.\n",
    "Lead Origin_Lead Add Form\n",
    "Lead Source_Direct Traffic\n",
    "Lead Source_Google\n",
    "Lead Source_Welingak Website\n",
    "Lead Source_Organic Search\n",
    "Lead Source_Referral Sites\n",
    "Lead Source_Welingak Website\n",
    "Do Not Email_Yes\n",
    "Last Activity_Email Bounced\n",
    "Last Activity_Olark Chat Conversation\n",
    "Keeping these in mind the X Education can flourish as they have a very high chance to get almost all the potential buyers to change their mind and buy their courses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
